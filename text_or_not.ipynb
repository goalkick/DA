{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from xml.etree import ElementTree\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textPath='./Text'\n",
    "nontextPath='./Nontext'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Width(a):\n",
    "    return int(a['Right'])-int(a['Left'])\n",
    "def Height(a):\n",
    "    return int(a['Bottom'])-int(a['Top'])\n",
    "def Area(a):\n",
    "    return Width(a)*Height(a)\n",
    "def w2f(x):\n",
    "    feature=[]\n",
    "    a=x.attrib\n",
    "    sizes=x[0].attrib\n",
    "    \n",
    "    area=Area(sizes)\n",
    "    width=Width(sizes)\n",
    "    height=Height(sizes)\n",
    "    blackCount=int(a['BlackCount'])\n",
    "    horzStrokeCount=int(a['HorzStrokesCount'])\n",
    "    vertStrokeCount=int(a['VertStrokesCount'])\n",
    "    maxHorzStrokeLength=int(a['MaxHorzStrokeLength'])\n",
    "    whiteHolesCount=int(a['WhiteHolesCount'])\n",
    "\n",
    "    feature.append((area-blackCount) / ((horzStrokeCount + height)*height) )\n",
    "    feature.append((horzStrokeCount+vertStrokeCount)/max(width, height))\n",
    "    feature.append(blackCount/(horzStrokeCount+vertStrokeCount))\n",
    "\n",
    "    feature.append(maxHorzStrokeLength/horzStrokeCount)\n",
    "    feature.append(blackCount/area)\n",
    "    feature.append(whiteHolesCount)\n",
    "    feature.append(100*whiteHolesCount/horzStrokeCount)\n",
    "    feature.append(100*whiteHolesCount/vertStrokeCount)\n",
    "    feature.append(100*vertStrokeCount/width)\n",
    "    feature.append(100*horzStrokeCount/height)\n",
    "        \n",
    "    return feature\n",
    "    \n",
    "def getFeatures(f):\n",
    "    xml=ElementTree.parse(f)\n",
    "    features=[]\n",
    "    for x in xml.iter(\"WordFragment\"):\n",
    "        textFeature=w2f(x)\n",
    "        if len(textFeature) > 0:\n",
    "            features.append(textFeature)\n",
    "    return features\n",
    "        \n",
    "def getTrainFromXML(path):\n",
    "    train = []\n",
    "    \n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('.xml'):\n",
    "            a=getFeatures(path+'/'+f)\n",
    "            \n",
    "            train += a\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_text=getTrainFromXML(textPath)\n",
    "Y_text=[1 for x in X_text]\n",
    "X_nontext=getTrainFromXML(nontextPath)\n",
    "Y_nontext=[0 for x in X_nontext]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=X_text+X_nontext\n",
    "y=Y_text+Y_nontext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier()\n",
    "gb=GradientBoostingClassifier()\n",
    "svc=LinearSVC()\n",
    "lg=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest f1=0.847734223648\n",
      "GradientBoosting f1=0.844894400101\n",
      "LinearSVC f1=0.626072951996\n",
      "LogisticRegression f1=0.84151447973\n"
     ]
    }
   ],
   "source": [
    "print 'Random Forest f1={}'.format(np.mean(cross_val_score(rf, X, y, cv=10, scoring='f1')))\n",
    "print 'GradientBoosting f1={}'.format(np.mean(cross_val_score(gb, X, y, cv=10, scoring='f1')))\n",
    "print 'LinearSVC f1={}'.format(np.mean(cross_val_score(svc, X, y, cv=10, scoring='f1')))\n",
    "print 'LogisticRegression f1={}'.format(np.mean(cross_val_score(lg, X, y, cv=10, scoring='f1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'sqrt', 'n_estimators': 40, 'criterion': 'entropy'}\n",
      "0.853174781932\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parRF = [{'n_estimators': [20, 30, 40, 50],\n",
    "              'max_features': [None, 'sqrt', 'log2'],\n",
    "              'criterion': ['gini', 'entropy']}]\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(), parRF, cv=10, scoring='f1')\n",
    "clf.fit(X, y)\n",
    "print(clf.best_params_)\n",
    "print(max(clf.cv_results_['mean_test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'sqrt', 'loss': 'exponential', 'n_estimators': 100}\n",
      "0.849316226989\n"
     ]
    }
   ],
   "source": [
    "parGB = [{'n_estimators': [100, 250],\n",
    "              'max_features': [None, 'sqrt', 'log2'],\n",
    "              'loss': ['deviance', 'exponential']}]\n",
    "\n",
    "clf = GridSearchCV(GradientBoostingClassifier(), parGB, cv=10, scoring='f1')\n",
    "clf.fit(X, y)\n",
    "print(clf.best_params_)\n",
    "print(max(clf.cv_results_['mean_test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l2', 'C': 0.1}\n",
      "0.842295972135\n"
     ]
    }
   ],
   "source": [
    "parLG = [{'penalty': ['l2', 'l1'],\n",
    "              'C': [0.1, 0.5, 1.0, 10.0, 100.0]}]\n",
    "\n",
    "clf = GridSearchCV(LogisticRegression(), parLG, cv=10, scoring='f1')\n",
    "clf.fit(X, y)\n",
    "print(clf.best_params_)\n",
    "print(max(clf.cv_results_['mean_test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anton\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(max_features='sqrt',n_estimators=40,criterion='entropy')\n",
    "rf.fit(x_train, y_train)\n",
    "y_rf=rf.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb=GradientBoostingClassifier(max_features='sqrt',n_estimators=100,loss='exponential')\n",
    "gb.fit(x_train, y_train)\n",
    "y_gb=gb.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lg=LogisticRegression(penalty='l2',C=0.1)\n",
    "lg.fit(x_train, y_train)\n",
    "y_lg=lg.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_all=[int((y_lg[i][1]+y_gb[i][1]+y_rf[i][1])>1.5) for i in xrange(len(y_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88252090556801965"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
